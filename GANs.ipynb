{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi8F/HhtOOjPGmm9A+InD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitaxdeshpande/nikitaxdeshpande/blob/main/GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "#BUILDING A GAN MODEL IN PyTorch: GENERATOR\n",
        "import torch.nn as nn # import the torch.nn module and alias it as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(seq_length, seq_length),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sBX48daKfXE8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(sq_length, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n"
      ],
      "metadata": {
        "id": "CQSRCeEJc74g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "source": [
        "#BUILDING A GAN MODEL IN PyTorch: GENERATOR\n",
        "import torch.nn as nn # import the torch.nn module and alias it as nn\n",
        "\n",
        "# Define seq_length\n",
        "seq_length = 100 # Example value, set to the desired sequence length\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(seq_length, seq_length),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Q3OjWHtHf5Wn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "source": [
        "#Training the discriminator\n",
        "\n",
        "import torch\n",
        "\n",
        "# Example real_data (replace with your actual data)\n",
        "real_data = torch.randn(seq_length)\n",
        "\n",
        "# Instantiate the discriminator\n",
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "\n",
        "criterion = nn.BCELoss() # Example: Binary Cross Entropy Loss\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters())\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "  for real_data_item in real_data.unsqueeze(0): # Changed loop variable to avoid shadowing\n",
        "    noise = torch.rand((1, seq_length))\n",
        "    disc_real = discriminator(real_data_item) # Use real_data_item here\n",
        "    fake_data = generator(noise)\n",
        "    disc_fake = discriminator(fake_data.detach())\n",
        "    loss_disc = criterion(disc_real, torch.ones_like(disc_real))+ criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "    optimizer_discriminator.zero_grad()\n",
        "    loss_disc.backward()\n",
        "    optimizer_discriminator.step()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "F1uEMsHMgTJ3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "source": [
        "#Building the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(seq_length, 1), # Changed sq_length to seq_length\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "04r7M_mxgrUb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "source": [
        "#Building the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(seq_length, 1), # Changed sq_length to seq_length\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "GIGYR4GvggAu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the Generator\n",
        "import torch\n",
        "# Instantiate the discriminator\n",
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "\n",
        "criterion = nn.BCELoss() # Example: Binary Cross Entropy Loss\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters())\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters()) # Define optimizer_generator\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "  for real_data_item in real_data.unsqueeze(0): # Changed loop variable to avoid shadowing\n",
        "    # Discriminator training\n",
        "    noise = torch.rand((1, seq_length))\n",
        "    disc_real = discriminator(real_data_item) # Use real_data_item here\n",
        "    fake_data = generator(noise)\n",
        "    disc_fake = discriminator(fake_data.detach())\n",
        "    loss_disc = criterion(disc_real, torch.ones_like(disc_real))+ criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "    optimizer_discriminator.zero_grad()\n",
        "    loss_disc.backward()\n",
        "    optimizer_discriminator.step()\n",
        "\n",
        "    #Generator training\n",
        "    disc_fake = discriminator(fake_data)\n",
        "    loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n",
        "    optimizer_generator.zero_grad() # Now you can use optimizer_generator\n",
        "    loss_gen.backward()\n",
        "    optimizer_generator.step()\n",
        "    if (epoch+1)%10 == 0:\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs}:\\t\\\n",
        "            Generator loss: {loss_gen.item()}\\t\\\n",
        "            Discriminator loss: {loss_disc.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEUgx4jpeFFz",
        "outputId": "43678960-891e-4163-a5b2-4ca296d15001"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50:\t            Generator loss: 0.4518023133277893\t            Discriminator loss: 1.33694589138031\n",
            "Epoch 20/50:\t            Generator loss: 0.4350324273109436\t            Discriminator loss: 1.281173825263977\n",
            "Epoch 30/50:\t            Generator loss: 0.506084144115448\t            Discriminator loss: 1.123232126235962\n",
            "Epoch 40/50:\t            Generator loss: 0.5490851402282715\t            Discriminator loss: 1.0410257577896118\n",
            "Epoch 50/50:\t            Generator loss: 0.6610575318336487\t            Discriminator loss: 0.8881955146789551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing Real and Generated Data\n",
        "\n",
        "print(\"\\nReal Data: \")\n",
        "print(real_data[:5]) # Changed 'data' to 'real_data'\n",
        "\n",
        "print(\"\\nGenerated Data: \")\n",
        "for _ in range(5):\n",
        "  noise = torch.rand((1, seq_length))\n",
        "  generated_data = generator(noise)\n",
        "  print(torch.round(generated_data).detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0G1KPOGerO-",
        "outputId": "3fb1a824-80f5-49f5-90d8-15682bd11672"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Real Data: \n",
            "tensor([-0.1439, -2.1032, -0.6928,  1.4095, -0.3166])\n",
            "\n",
            "Generated Data: \n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
            "         0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "         1., 1., 0., 0., 1., 1., 0., 0., 1., 0.]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
            "         0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "         1., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
            "         0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "         1., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
            "         0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "         1., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
            "tensor([[0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
            "         0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "         1., 1., 0., 0., 1., 1., 0., 0., 1., 0.]])\n"
          ]
        }
      ]
    }
  ]
}